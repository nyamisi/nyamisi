---
title: "Machine Learning (ML) using Regression Algorithm in R"
author: "Nyamisi Peter"
date: "2023-03-13"
categories: [code, ML & AI]
image: "randomForestscreenShort.jpg"
bibliography: "../blog.bib"
code-line-numbers: true

---

# Introduction

In the previous  [post](https://nyamisi.github.io/nyamisi/posts/machine-learning-classification/) we saw how classification algorithm may be applied in machine learning (ML). In this post we are going to look the application of regression algorithm in machine learning. We will use penguins data from the **palmerpenguins** package [@penguin20]. It includes measurements for penguin species, island in Palmer Archipelago, size (flipper length, body mass, bill dimensions), and sex.

First, we will load the packages which we are going to use in this post; I will use `require()` function, but you may also use `library()` function depending on your preferences. The `tidyverse` is a collection of R packages that are designed to work together to make data manipulation and analysis easier and more efficient. Tidyverse is used as a workflow from data preprocessing to model fitting and evaluation. The packages in the Tidyverse, such as `dplyr` and `ggplot2`, will be used in data manipulation and plotting of graphs respectively. 

`Tidymodels`, on the other hand, is a collection of R packages for modeling and machine learning tasks. Tidymodels includes packages such as `rsample` for the initial splitting and training of the data, `parsnip` for specifying and fitting models, and `yardstick` for evaluating model performance. The `ranger` package will be used in setting the engine in **random forest** model.

The data used will come from `palmerpenguins` package. 

```{r}
#| warning: false
#| message: false
#| 
require(tidyverse)
require(tidymodels)
require(ranger)
require(palmerpenguins)

```

## Data loading and preprocessing

After loading the packages, load the penguins data [@penguin20] and remove all the missing values in the dataset. Name the dataset as ***penguin.data***. The dataset consist of 333 rows and 8 columns

```{r}
#| warning: false
#| message: false
penguin.data = palmerpenguins::penguins %>% 
  drop_na()

penguin.data
```

Then, observe the internal structure of the dataset using `glimpse()` function of **dplyr** package. The dataset consist of 8 variables (columns); 3 are factors data (species, island and sex), 2 numeric or double data (bill_length_mm, bill_depth_mm) and 3 integers (flipper_length_mm, body_mass_g, year).

```{r}
#| warning: false
#| message: false
glimpse(penguin.data)
```

In this post we will use four variables from penguins data; which are bill_length_mm, bill_depth_mm, flipper_length_mm and body_mass_g. Use the `select()` function of **dplyr** package [@dplyr] to select the variables of interest.

```{r}
#| warning: false
#| message: false
penguin.data = penguin.data %>% 
  select(flipper_length_mm, 
         bill_length_mm, 
         bill_depth_mm,
         body_mass_g)

penguin.data
```

Before we apply ML regression algorithms, first we will look on the distribution of the response variable (body_mass_g). Our response variable ranges from around 2700 to 6700 grams with the median value at around 4050 grams [@fig-density]. 


```{r}
#| label: fig-density
#| fig-cap: The distribution of the body mass of Penguin species. The vertical dashed red line indicate the median body mass
#| fig-width: 4
#| fig-height: 3
penguin.data %>% 
  mutate(med.mass = median(body_mass_g, na.rm = T)) %>% #median value = 4050
  ggplot(aes(x = body_mass_g))+
  geom_density(fill = "cyan3", alpha = 0.3)+
  geom_vline(xintercept =  4050, color = "red", linetype = "dashed")+
  theme_bw()
```



## Data Spliting

Regression algorithm as one of the supervised learning, needs two data types; the **training** and **testing** data set. The `penguin.data` will be split into two groups; training and testing dataset. The training dataset will have a proportion of 70% and the testing data will carry 30% of the total data. In total, our dataset has 333 observations in which 233 samples will be used to train the model while in validation of the accuracy of the model, we will use the testing set with 100 samples.

```{r}
#| warning: false
#| message: false

set.seed(123)
split.penguin = penguin.data %>% 
  initial_split(prop = 0.7)

split.penguin
```

The training data below with 233 samples will be used to training the model;

```{r}
#| warning: false
#| message: false
train.set = split.penguin %>% 
  training()

train.set
```

The testing data with 100 observations will be used to test the accuracy of the model

```{r}
#| warning: false
#| message: false
test.set = split.penguin %>% 
  testing()

test.set
```

## Model specification

In order to perform the predictions on the body weight of the penguin species, we will use two different regression model types; The **Random Forest** and the **Linear Regression** model. The regression algorithm is applied when the response variable is numeric. We will look at one model after another and then at the end we will compare the best model among the two.

### Random forest model

First, we will specify the model type as random forest using the `rand_forest()` function of the **parsnip** package [@parsnip22]. The set engine **ranger** and the mode **regression** will be used. 

Finally, the model will be fitted with the train data set using the `fit()` function of the **parsnip** package [@parsnip22] with the response variable as **body_mass_g**.



```{r}
#| warning: false
#| message: false
mod.rf = rand_forest() %>% 
  set_engine(engine = "ranger") %>% 
  set_mode(mode = "regression") %>% 
  fit(body_mass_g~., data = train.set)

mod.rf
```

The summary of the fitted model shows the R-squared value is 0.80. This shows that 80% of our data fits better to the model.

#### Model Validation

Then, we will evaluate the model's performance on the testing data using the `predict()` function of **stats** package [@r]. The model have achieved predictions of body weight of the penguins using the test data set which was not used in data training. The values of the predictions are within the distribution ranges of the response variable.

```{r}
pred.rf = mod.rf %>% 
  predict(test.set) %>% 
  bind_cols(test.set)

pred.rf
```

#### Accuracy testing

After validating the model performance, then we need to test its accuracy using the `metrics()` function of **yardstick** package [@yardstick22]. The data used will be the output of the trained model (*pred.rf*), the **truth** variable will be the actual values of the body mass and the estimate variable will be the the predicted values of the body mass. 

```{r}
bb = pred.rf %>% 
  metrics(truth = body_mass_g,
          estimate = .pred)

bb
```

The accuracy result shows the R-squared value of `r bb$.estimate[2] %>% round(2)` meaning that our model is accurate for more than 80%. Other performance indicators like **Root Mean Squared Error (RMSE)** and the **Mean Absolute Error (MAE)** are also low. The RMSE measures the average difference between values predicted by a model and the actual values while the MAE measures the average absolute error between actual and predicted values.

#### Model predictions on the new data

Finally, we will use the tuned model to make predictions on new data. First we will create the new dataset using the `rnorm()` function of R software [@r]. We will name our new data as **data.new**.


```{r}
data.new = tibble(bill_depth_mm = rnorm(n = 10,
                                  mean = 15, 
                                  sd = 3),
            bill_length_mm = rnorm(n = 10,
                                   mean = 50, 
                                   sd = 10),
            flipper_length_mm = rnorm(n = 10,
                                      mean = 195,
                                      sd = 50))

mod.rf %>% 
  predict(data.new) %>% 
  bind_cols(data.new) %>% 
  mutate(.pred = as.integer(.pred))

```

That's great!!

Our model has predicts the body mass for the penguin species for the new data. 

### Linear regression model

When using the linear regression model we will first specify the model type as Linear Regression using the `linear_reg()` function of the **parsnip** package [@parsnip22]. The set engine **lm** and the mode **regression** will be used. 

Finally, the model will be fitted with the train data set using the `fit()` function of the **parsnip** package [@parsnip22] with the response variable as **body_mass_g**.

```{r}
#| warning: false
#| message: false
mod.lm = linear_reg() %>% 
  set_engine(engine = "lm") %>% 
  set_mode(mode = "regression") %>% 
  fit(body_mass_g~., data = train.set %>% select(-flipper_length_mm))

mod.lm
```

#### Model Validation

Then, we will evaluate the model's performance on the testing data using the `predict()` function of **stats** package [@r]. Our model has predicted for the body weight values of the penguins.

```{r}
pred.lm = mod.lm %>% 
  predict(test.set) %>% 
  bind_cols(test.set)

pred.lm
```

#### Accuracy testing

The model accuracy will be tested using the `metrics()` function of **yardstick** package [@yardstick22]. 



```{r}
cc = pred.lm %>% 
  metrics(truth = body_mass_g,
          estimate = .pred)

cc
```


The accuracy result shows the R-square is `r cc$.estimate[2] %>% round(2)`, RMSE is `r cc$.estimate[1] %>% round(2)` and the MAE value is `r cc$.estimate[3] %>% round(2)`. 

## Comparison between the two models

We have seen the performance of each model. We have to choose which model is more accurate and performs better than the other. I will join the two accuracy test results; the one from the random forest and the other from the linear regression model (@tbl-model-best). 

```{r}
#| label: tbl-model-best
#| tbl-cap: The table showing the model performance indicators
pred.rf %>% 
  metrics(truth = body_mass_g,
          estimate = .pred) %>% 
  pivot_wider(names_from = .metric, 
              values_from = .estimate) %>% 
  mutate(model = "Random Forest") %>% 
  select(Model = 5, Rsquare=3, RMSE=2, MAE=4) %>% 
  bind_rows(
    
pred.lm %>% 
  metrics(truth = body_mass_g,
          estimate = .pred)  %>% 
  pivot_wider(names_from = .metric, 
              values_from = .estimate) %>% 
  mutate(model = "Linear Regression") %>% 
  select(Model = 5, Rsquare=3, RMSE=2, MAE=4)
) %>% 
  mutate(across(is.numeric, round, 2))  %>% 
  gt::gt()

```

The table shows that the Random Forest is the best than the Linear Regression Model!! This is because it has higher R-squared value with low RMSE and MAE values (@tbl-model-best).


```{r}
#| eval: false
#| include: false
mod.lm %>% 
  tidy(interval = TRUE) %>% 
  slice(-1) %>% 
  ggplot(aes(y = statistic, x = term)) +
  geom_errorbar(aes(ymin = statistic - std.error, 
                    ymax = statistic + std.error), 
                width = 0.05)+
  geom_point(size = 4)
```

## Summary


All in all, the success of machine learning and artificial intelligence depend on the **quality of the data**, the **complexity of the problem**, and the **choice of the appropriate algorithms** and techniques [@han11; @witten05].

The quality of the data is one of the most important factors for the success of machine learning. The data should be accurate, complete, and representative of the problem domain [@han11; @witten05]. In addition, the data should be properly labeled and preprocessed to ensure that the machine learning algorithms can effectively learn from it.

The complexity of the problem is also a key factor in determining the success of machine learning [@gomez14]. Some problems are inherently more complex than others, and require more sophisticated algorithms and techniques to solve. For example, image recognition and natural language processing are typically more complex than simple regression problems.

Finally, the choice of the appropriate algorithms and techniques is critical for the success of machine learning [@sarker21; @gomez14]. Different algorithms and techniques are suited for different types of problems, and the choice of the appropriate one will depend on the specific problem and the available data. Additionally, the parameters and hyperparameters of the algorithms need to be properly tuned to ensure that the models are optimized for the problem at hand.

::: callout-note

Don't miss out our next post in this blog!!!

:::
## Consultated references
