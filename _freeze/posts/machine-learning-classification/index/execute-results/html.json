{
  "hash": "88790ddb7efe112b58a9add059b95be4",
  "result": {
    "markdown": "---\ntitle: \"Machine Learning (ML) using classification Algorithm in R\"\nauthor: \"Nyamisi Peter\"\ndate: \"2023-03-08\"\ncategories: [code, ML & AI]\nimage: \"ML-image.jpg\"\nbibliography: \"../blog.bib\"\n---\n\n\n# Introduction\n\nTechnology is becoming more important in our daily lives in every second. In order to keep up with the pace of these technological changes, scientists are more heavily learning different algorithms to make things easier so as to meet consumer's demand. These technologies are commonly associated with artificial intelligence, machine learning, deep learning, and neural networks.\n\n**Machine learning (ML)** and **artificial intelligence (AI)** are closely related concepts that are often used interchangeably, but they are not the same thing.\n\n**Artificial intelligence** refers to the ability of machines to mimic human cognitive functions such as learning, reasoning, and problem-solving [IBM](https://www.ibm.com/cloud/blog/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks). AI encompasses a wide range of techniques and approaches, including rule-based systems, expert systems, and machine learning. It is used to predict, automate, and optimize tasks that humans have historically done, such as speech and facial recognition, decision making, and translation.\n\n**Machine learning** is a specific type of AI that involves the development of algorithms that can learn from data and make predictions or decisions based on that data [@mitchell07]. In other words, machine learning algorithms are designed to learn patterns and relationships in data without being explicitly programmed to do so.\n\n![Machine learning](ML-image.jpg)\n\n## Machine Learning Algorithms\n\nThere are several types of machine learning algorithms, including **supervised learning**, **unsupervised learning**, and **reinforcement learning**. Supervised learning involves using labeled (predictor) training data to train a model to make predictions on new, unseen data. Unsupervised learning involves finding patterns and relationships in data without the use of labeled training data. Reinforcement learning involves training a model to make decisions based on feedback in the form of rewards or punishments.\n\n**Classification and regression** are two of the most common types of supervised learning algorithms in machine learning and artificial intelligence. Classification is a type of supervised learning algorithm used for predicting discrete or categorical outcomes. It involves mapping input variables to discrete output categories or labels. The objective of classification is to build a model that accurately assigns new data points to the correct class or label.\n\nOn the other hand, regression is a type of supervised learning algorithm used for predicting continuous or numeric outcomes. It involves mapping input variables to continuous output values. The objective of regression is to build a model that accurately predicts the value of the dependent variable based on the values of the independent variables.\n\n![Difference between classification and regression](class-regression.jpg)\n\nIn this tutorial we are going to deal with classification algorithm in predicting the type of penguin species flipper length, bill dimensions and sex. We will use penguins data from the **palmerpenguins** package [@penguin20]. It includes measurements for penguin species, island in Palmer Archipelago, size (flipper length, body mass, bill dimensions), and sex.\n\nFirst, we will load the packages which we are going to use in this tutorial; I will use `require()` function, but you may also use `library()` function depending on your preferences.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrequire(tidyverse)\nrequire(tidymodels)\nrequire(palmerpenguins)\nrequire(ranger)\nrequire(patchwork)\n```\n:::\n\n\n## Data\n\nAfter loading the packages, we will load the penguins data [@penguin20] and remove all the missing values in the dataset and equate them as ***penguin.data***. The dataset consist of 333 rows and 8 columns\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin.data = palmerpenguins::penguins %>% \n  drop_na()\n\npenguin.data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 333 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           36.7          19.3               193        3450\n 5 Adelie  Torgersen           39.3          20.6               190        3650\n 6 Adelie  Torgersen           38.9          17.8               181        3625\n 7 Adelie  Torgersen           39.2          19.6               195        4675\n 8 Adelie  Torgersen           41.1          17.6               182        3200\n 9 Adelie  Torgersen           38.6          21.2               191        3800\n10 Adelie  Torgersen           34.6          21.1               198        4400\n# ℹ 323 more rows\n# ℹ 2 more variables: sex <fct>, year <int>\n```\n:::\n:::\n\n\nThen, we will look on the internal structure of the dataset using `glimpse()` function of **dplyr** package. Our dataset consist of 8 variables (columns); 3 are factors data (species, island and sex), 2 numeric or double data (bill_length_mm, bill_depth_mm) and 3 integers (flipper_length_mm, body_mass_g, year). The variable species have 3 different levels which are *Adelie*, *Gentoo* and *Chinstrap*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(penguin.data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 333\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, 36.7, 39.3, 38.9, 39.2, 41.1, 38.6…\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, 19.3, 20.6, 17.8, 19.6, 17.6, 21.2…\n$ flipper_length_mm <int> 181, 186, 195, 193, 190, 181, 195, 182, 191, 198, 18…\n$ body_mass_g       <int> 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3200, 3800…\n$ sex               <fct> male, female, female, female, male, female, male, fe…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n```\n:::\n:::\n\n\nIn this tutorial we will use only three variables from penguins data; which are species, bill_length_mm, bill_depth_mm. We will run the `select()` function of **dplyr** package [@dplyr] to select our variables of interest\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin.data = penguin.data %>% \n  select(species, \n         bill_length_mm, \n         bill_depth_mm)\n```\n:::\n\n\nBefore we apply ML algorithms, first we will crosscheck whether the predictor variable (in this case, species), have distinct features (like size) which will help in providing the more accurate output during predictions. When there is interconnection or inter-relation between response variables, some confusion might arise during predictions.\n\nWe will use scatter plot between bill_length_mm and bill_depth_mm to see the distribution of each species in the dataset. There is a distinct differences between the size of the three penguins species (@fig-scatter). Each species has its size range; therefore, the dataset fit best in our analysis.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npenguin.data %>% \n  ggplot(aes(y = bill_length_mm, \n             x = bill_depth_mm, \n             color = species)) +\n  geom_point() +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![Scatter plot showing the distribution of *Adelie*, *Gentoo* and *Chinstrap* species](index_files/figure-html/fig-scatter-1.png){#fig-scatter fig-align='center' width=480}\n:::\n:::\n\n\n## Classification algorithm\n\nAs explained earlier, supervised learning involves training a dataset before you have your predictions. Since our output is categorical (prediction of the species type), then we will use classification algorithm in our analysis.\n\n### Data Spliting\n\nClassification algorithm as one of the supervised learning, needs two data types; the **training** and **testing** data set. Our `penguin.data` will be split into these two groups. The training dataset will have a proportion of 70% and the remaining 30% will be the test dataset. In total, our dataset has 333 observations in which 233 samples will be used to train our model while in testing the accuracy of the model 100 samples will used.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsplit.penguin = penguin.data %>% \n  initial_split(prop = 0.7)\n\nsplit.penguin\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<Training/Testing/Total>\n<233/100/333>\n```\n:::\n:::\n\n\nThe training data below with 233 samples will be used for training the model;\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain.set = split.penguin %>% \n  training()\n\ntrain.set\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 233 × 3\n   species   bill_length_mm bill_depth_mm\n   <fct>              <dbl>         <dbl>\n 1 Adelie              36.2          17.2\n 2 Gentoo              48.7          15.1\n 3 Chinstrap           49.8          17.3\n 4 Chinstrap           54.2          20.8\n 5 Gentoo              44.9          13.3\n 6 Chinstrap           50.7          19.7\n 7 Adelie              38.6          17  \n 8 Gentoo              46.2          14.9\n 9 Gentoo              50.1          15  \n10 Adelie              39.8          19.1\n# ℹ 223 more rows\n```\n:::\n:::\n\n\nThe testing data with 100 observations will be used to test the accuracy of the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest.set = split.penguin %>% \n  testing()\n\ntest.set\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 100 × 3\n   species bill_length_mm bill_depth_mm\n   <fct>            <dbl>         <dbl>\n 1 Adelie            40.3          18  \n 2 Adelie            38.9          17.8\n 3 Adelie            38.6          21.2\n 4 Adelie            42.5          20.7\n 5 Adelie            37.8          18.3\n 6 Adelie            37.7          18.7\n 7 Adelie            35.9          19.2\n 8 Adelie            38.8          17.2\n 9 Adelie            35.3          18.9\n10 Adelie            40.5          17.9\n# ℹ 90 more rows\n```\n:::\n:::\n\n\n#### Data training\n\nUse the ***train.set*** data to train the model. Run the `rand_forest()` of the **parsnip** package [@parsnip22], set engine as **ranger** and the mode as **classification**. Fit the train data set with the response be the **species**. The summary of the training model will be shown with the predictions error of 0.02 equivalent to 2%.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod = rand_forest() %>% \n  set_engine(engine = \"ranger\") %>% \n  set_mode(mode = \"classification\") %>% \n  fit(species~., data = train.set)\n\nmod\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nparsnip model object\n\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  500 \nSample size:                      233 \nNumber of independent variables:  2 \nMtry:                             1 \nTarget node size:                 10 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.03958214 \n```\n:::\n:::\n\n\n#### Predictions\n\nThen, the ***test.set*** data will be used in predictions of the type of the species provided we have the bill length and bill depth. The predicted class and the test dataset will be binded together to see if there is a match or mismatch of the predicted versus the actual species type.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf.pred = mod %>% \n  predict(test.set) %>% \n  bind_cols(test.set)\n\nrf.pred\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 100 × 4\n   .pred_class species bill_length_mm bill_depth_mm\n   <fct>       <fct>            <dbl>         <dbl>\n 1 Adelie      Adelie            40.3          18  \n 2 Adelie      Adelie            38.9          17.8\n 3 Adelie      Adelie            38.6          21.2\n 4 Adelie      Adelie            42.5          20.7\n 5 Adelie      Adelie            37.8          18.3\n 6 Adelie      Adelie            37.7          18.7\n 7 Adelie      Adelie            35.9          19.2\n 8 Adelie      Adelie            38.8          17.2\n 9 Adelie      Adelie            35.3          18.9\n10 Adelie      Adelie            40.5          17.9\n# ℹ 90 more rows\n```\n:::\n:::\n\n\n#### Accuracy testing\n\nWe have already predicted for the results, then we need to test for the accuracy of the model. The model is considered accurate when its accuracy value is higher or equal to 80%. The obtained accuracy of our model is 0.98 (98%) and the kap 96%. Our model can then be used to predict the type of species provided you have the bill length and the bill depth of the penguins.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf.pred %>% \n  metrics(truth = species,\n          estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy multiclass     0.94 \n2 kap      multiclass     0.905\n```\n:::\n:::\n\n\nNow, we need to see the accuracy for each predicted species versus the actual type. We will use `conf_mat()` of the ***yardstick*** package [@yardstick22]. The result indicate that 43 *Adelie* were correctly predicted while 1 *Chinstrap* was incorrectly predicted as *Adelie*. While 16 *Chinstrap* were correctly predicted, 1 of this species was wrongly predicted as *Gentoo*. On the other hand, all 39 *Gentoo* were correctly predicted.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf.pred %>% \n  conf_mat(truth = species, \n           estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           Truth\nPrediction  Adelie Chinstrap Gentoo\n  Adelie        46         1      0\n  Chinstrap      2        17      2\n  Gentoo         0         1     31\n```\n:::\n:::\n\n\nThen, we need to calculate the probability of each observation be accurate for every species. We will use `predict()` function of \\***stats** package of R [@r].\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf.preda = mod %>% \n  predict(test.set, \n          type = \"prob\") %>% \n  bind_cols(test.set)\n\nrf.preda\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 100 × 6\n   .pred_Adelie .pred_Chinstrap .pred_Gentoo species bill_length_mm\n          <dbl>           <dbl>        <dbl> <fct>            <dbl>\n 1        1             0           0        Adelie            40.3\n 2        0.997         0.00313     0        Adelie            38.9\n 3        0.996         0.00396     0        Adelie            38.6\n 4        0.796         0.182       0.0223   Adelie            42.5\n 5        0.999         0.00075     0        Adelie            37.8\n 6        0.989         0.0107      0        Adelie            37.7\n 7        0.998         0.00156     0        Adelie            35.9\n 8        0.996         0.00327     0.000286 Adelie            38.8\n 9        0.997         0.003       0        Adelie            35.3\n10        1             0           0        Adelie            40.5\n# ℹ 90 more rows\n# ℹ 1 more variable: bill_depth_mm <dbl>\n```\n:::\n:::\n\n\n#### Roc Curve\n\nThe probability results will then be used to plot the roc curve (@fig-roc-curve). The `roc_curve()` function of ***yardstick*** package [@yardstick22] will be used supplied with species, .pred_Adelie, .pred_Chinstrap, and .pred_Gentoo. The `autoplot()` function of the ***workflowsets*** package [@workflowsets22] will then be applied to create the curve. The curve shows that *Adelie* species fitted better to the model than other the *Gentoo* and *Chinstrap* species (@fig-roc-curve).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf.preda %>% \n  roc_curve(species, \n            .pred_Adelie, \n            .pred_Chinstrap, \n            .pred_Gentoo) %>% \n  autoplot()+\n  ggpubr::theme_pubclean()+\n  theme(strip.background = element_blank())\n```\n\n::: {.cell-output-display}\n![The ROC curve of *Adelie*, *Chinstrap* and *Gentoo* species](index_files/figure-html/fig-roc-curve-1.png){#fig-roc-curve width=528}\n:::\n:::\n\n\n#### Model validation for the future data\n\nIn order to validate whether the model works to other newly collected data, we will validate it using the created data consists of bill length and depth. The data will be applied to the model and test if the prediction of the type of species will be done. The new created data will be named as ***new.penguin*** containing three observations;\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew.penguin = tibble(bill_length_mm = c(35,47.5, 70),\n                     bill_depth_mm = c(13,17, 18))\n\nnew.penguin\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n  bill_length_mm bill_depth_mm\n           <dbl>         <dbl>\n1           35              13\n2           47.5            17\n3           70              18\n```\n:::\n:::\n\n\nThen, the model will be applied and see if it will predict the type of species. We will use `predict()` function.\n\nHoolah!! the model give us the predicted species as *Adelie* and *Chinstrap*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod %>% \n  predict(new.penguin)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 1\n  .pred_class\n  <fct>      \n1 Adelie     \n2 Chinstrap  \n3 Chinstrap  \n```\n:::\n:::\n\n\nWe will also create another data named as ***aa*** with 10 observations using `rnorm()` function of **stats** package [@r]. We will also predict the type of species for these data using our model. Again the model works and give us predictions!!\n\n\n::: {.cell}\n\n```{.r .cell-code}\naa = tibble(bill_depth_mm = rnorm(n = 10,\n                                  mean = 15, \n                                  sd = 3),\n            bill_length_mm = rnorm(n = 10,\n                                   mean = 50, \n                                   sd = 10))\n\nmod %>% \n  predict(aa) %>% \n  bind_cols(aa)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 3\n   .pred_class bill_depth_mm bill_length_mm\n   <fct>               <dbl>          <dbl>\n 1 Adelie               14.3           30.4\n 2 Gentoo               13.9           62.6\n 3 Gentoo               12.9           71.0\n 4 Chinstrap            18.0           50.5\n 5 Gentoo               13.4           53.5\n 6 Chinstrap            18.7           49.9\n 7 Gentoo               14.9           46.5\n 8 Adelie               17.2           30.2\n 9 Gentoo               14.7           53.5\n10 Gentoo               10.8           48.7\n```\n:::\n:::\n\n\n\n## Summary\n\n\nAll in all, the success of machine learning and artificial intelligence depend on the **quality of the data**, the **complexity of the problem**, and the **choice of the appropriate algorithms** and techniques [@han11; @witten05].\n\nThe quality of the data is one of the most important factors for the success of machine learning. The data should be accurate, complete, and representative of the problem domain [@han11; @witten05]. In addition, the data should be properly labeled and preprocessed to ensure that the machine learning algorithms can effectively learn from it.\n\nThe complexity of the problem is also a key factor in determining the success of machine learning [@gomez14]. Some problems are inherently more complex than others, and require more sophisticated algorithms and techniques to solve. For example, image recognition and natural language processing are typically more complex than simple regression problems.\n\nFinally, the choice of the appropriate algorithms and techniques is critical for the success of machine learning [@sarker21; @gomez14]. Different algorithms and techniques are suited for different types of problems, and the choice of the appropriate one will depend on the specific problem and the available data. Additionally, the parameters and hyperparameters of the algorithms need to be properly tuned to ensure that the models are optimized for the problem at hand.\n\n::: callout-note\n\nDon't miss out our next tutorial on Machine Learning (ML) using regression Algorithm!!!\n\n:::\n## Consultated references\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}